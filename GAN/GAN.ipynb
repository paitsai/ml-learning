{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入依赖\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义初始化方法\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:  # 对卷积层进行 He 初始化\n",
    "        nn.init.kaiming_normal_(m.weight.data, mode='fan_out', nonlinearity='relu')\n",
    "    elif classname.find('BatchNorm') != -1:  # 对 BatchNorm 层\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('Linear') != -1:  # 对全连接层\n",
    "        nn.init.kaiming_normal_(m.weight.data, mode='fan_out', nonlinearity='relu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    # 图片的尺度不变，只是改变了通道数量\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.LeakyReLU(0.22,inplace=True)\n",
    "        self.conv2 = nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # 如果输入和输出通道不同，使用 1x1 卷积调整维度\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=1)\n",
    "        else:\n",
    "            self.shortcut = None\n",
    "            \n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x  # 保存输入以进行跳跃连接\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.shortcut is not None:\n",
    "            identity = self.shortcut(x)\n",
    "\n",
    "        out += identity  # 加入跳跃连接\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G(nn.Module):\n",
    "    def __init__(self, in_dims=1024, out_dim=512):\n",
    "        super(G, self).__init__()\n",
    "        self.model = nn.Sequential()\n",
    "\n",
    "        self.fn1 = nn.Sequential(\n",
    "            nn.Linear(in_dims, out_dim * 128),\n",
    "            nn.BatchNorm1d(out_dim * 8 * 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # 第一层线性后 reshape\n",
    "        self.initial_conv = nn.ConvTranspose2d(in_channels=512*8, out_channels=256*4, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.BatchNorm2d1=nn.BatchNorm2d(1024)\n",
    "        self.second_conv = nn.ConvTranspose2d(256*4, 128, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.BatchNorm2d2=nn.BatchNorm2d(128)\n",
    "        self.resblock1 = ResBlock(128, 64)\n",
    "        self.third_conv = nn.ConvTranspose2d(64, 48, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.BatchNorm2d3=nn.BatchNorm2d(48)\n",
    "        self.resblock2 = ResBlock(48, 8)        \n",
    "        self.final_conv = nn.ConvTranspose2d(8, 3, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.fn1(x)\n",
    "        z = z.view(-1, 512*8, 4, 4)\n",
    "        z = self.initial_conv(z)\n",
    "        z=self.BatchNorm2d1(z)\n",
    "        z=self.second_conv(z)\n",
    "        z=self.BatchNorm2d2(z)\n",
    "\n",
    "        # 通过残差块\n",
    "        z = self.resblock1(z)\n",
    "        z=self.third_conv(z)\n",
    "        z=self.BatchNorm2d3(z)\n",
    "        \n",
    "        z = self.resblock2(z)\n",
    "\n",
    "        z = self.final_conv(z)\n",
    "        return self.tanh(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlock2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.LeakyReLU(0.2,inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # 如果输入和输出通道不同，使用 1x1 卷积调整维度\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        else:\n",
    "            self.shortcut = None\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x  # 保存输入以进行跳跃连接\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.shortcut is not None:\n",
    "            identity = self.shortcut(x)\n",
    "\n",
    "        out += identity  # 加入跳跃连接\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class D(nn.Module):\n",
    "    def __init__(self, in_dims=3, dims=64):\n",
    "        super(D, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential()\n",
    "\n",
    "        def conv_binary_2d(in_dim, out_dim):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_dim, out_dim, kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(out_dim),\n",
    "                nn.LeakyReLU(0.15)\n",
    "            )\n",
    "        \n",
    "        # 初始卷积层\n",
    "        # self.model.append(nn.Conv2d(in_dims, dims, kernel_size=10, stride=8, padding=1))\n",
    "        self.model.append(nn.Conv2d(in_dims, dims, kernel_size=3, stride=2, padding=1))  # 第一个卷积\n",
    "        nn.BatchNorm2d(dims),\n",
    "        self.model.append(nn.LeakyReLU(0.12))\n",
    "        \n",
    "      \n",
    "        self.model.append(conv_binary_2d(dims, 2 * dims))\n",
    "        nn.BatchNorm2d(2*dims)\n",
    "        self.model.append(ResBlock2(2 * dims, 4 * dims))  # 添加残差块\n",
    "        self.model.append(conv_binary_2d(4 * dims, 4 * dims))\n",
    "        nn.BatchNorm2d(4*dims)\n",
    "        self.model.append(ResBlock2(4 * dims, 2 * dims))  # 添加残差块\n",
    "        self.model.append(conv_binary_2d(2 * dims, 1 * dims))\n",
    "        nn.BatchNorm2d(1*dims)\n",
    "        nn.LeakyReLU(0.2,inplace=True)\n",
    "        # 输出层\n",
    "        self.model.append(nn.Conv2d(1 * dims, 1, kernel_size=4))\n",
    "        \n",
    "        self.sigm=nn.Sigmoid()\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.model(x)\n",
    "        z = z.view(-1)\n",
    "        z=self.sigm(z)\n",
    "        \n",
    "        return z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型参数设置\n",
    "batch_size=512\n",
    "feature_dim=128 #设置特征向量的大小\n",
    "\n",
    "lr=0.0002\n",
    "n_epoch=500\n",
    "\n",
    "workspace_dir = '.'\n",
    "save_dir=os.path.join(workspace_dir,'logs')\n",
    "os.makedirs(save_dir,exist_ok=True)\n",
    "\n",
    "G_model = G(in_dims=feature_dim).cuda()\n",
    "D_model = D(3).cuda()\n",
    "G_model.train()\n",
    "D_model.train()\n",
    "\n",
    "\n",
    "criterion=nn.BCELoss().to('cuda')\n",
    "opt_D = torch.optim.Adam(D_model.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "opt_G = torch.optim.Adam(G_model.parameters(), lr=lr, betas=(0.5, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: '.\\\\raw_GAN'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m GAN_dataset(root, transform\u001b[38;5;241m=\u001b[39mt)\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n\u001b[1;32m---> 62\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworkspace_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mraw_GAN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 59\u001b[0m, in \u001b[0;36mget_dataset\u001b[1;34m(root)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_dataset\u001b[39m(root):\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# 定义转换，包括调整大小和转换为张量\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     t \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m     55\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m)),\n\u001b[0;32m     56\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m     57\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m), (\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m)) \u001b[38;5;66;03m# Changing the pixel values in between -1 to 1 \u001b[39;00m\n\u001b[0;32m     58\u001b[0m ])\n\u001b[1;32m---> 59\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mGAN_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "Cell \u001b[1;32mIn[11], line 34\u001b[0m, in \u001b[0;36mGAN_dataset.__init__\u001b[1;34m(self, image_dir, transform)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m:param image_dir: 存储图像的目录\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m:param transform: 可选的转换操作\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_dir \u001b[38;5;241m=\u001b[39m image_dir\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_filenames \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: '.\\\\raw_GAN'"
     ]
    }
   ],
   "source": [
    "# 数据准备\n",
    "import random\n",
    "import numpy as np\n",
    "def same_seeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    np.random.seed(seed)  # Numpy module.\n",
    "    random.seed(seed)  # Python random module.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "same_seeds(0)\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class GAN_dataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        :param image_dir: 存储图像的目录\n",
    "        :param transform: 可选的转换操作\n",
    "        \"\"\"\n",
    "        \n",
    "        self.image_dir = image_dir\n",
    "        self.image_filenames = [f for f in os.listdir(image_dir) if f.endswith('.png')]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_dir, self.image_filenames[idx])\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "#这里可以加载自己想加载的数据\n",
    "from torchvision import transforms\n",
    "\n",
    "def get_dataset(root):\n",
    "    # 定义转换，包括调整大小和转换为张量\n",
    "    t = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Changing the pixel values in between -1 to 1 \n",
    "])\n",
    "    dataset = GAN_dataset(root, transform=t)\n",
    "    return dataset\n",
    "\n",
    "dataset = get_dataset(os.path.join(workspace_dir, 'raw_GAN'))\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(dataset[999])\n",
    "plt.imshow(dataset[999].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    for i,real_imgs in enumerate(dataloader):\n",
    "        batch_size = real_imgs.size(0)\n",
    "        real_imgs = real_imgs.to(device)\n",
    "        \n",
    "        z = torch.randn(batch_size, feature_dim).to(device)\n",
    "        fake_images = G_model(z)\n",
    "\n",
    "        # Ground truths\n",
    "        real_labels = torch.ones(batch_size).to(device)\n",
    "        fake_labels = torch.zeros(batch_size).to(device)\n",
    "\n",
    "        opt_D.zero_grad()\n",
    "        real_loss=criterion(torch.squeeze(D_model(real_imgs)),real_labels)\n",
    "        fake_loss=criterion(torch.squeeze(D_model(fake_images.detach())),fake_labels)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        opt_D.step()\n",
    "        \n",
    "        #####################\n",
    "        z = torch.randn(batch_size, feature_dim).to(device)\n",
    "        fake_images = G_model(z)\n",
    "        opt_G.zero_grad()\n",
    "        g_loss=criterion(torch.squeeze(D_model(fake_images)),real_labels)\n",
    "        g_loss.backward()\n",
    "        opt_G.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{n_epoch}] D_loss: {d_loss.item():.4f} G_loss: {g_loss.item():.4f}\")\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            with torch.no_grad():\n",
    "                z = torch.randn(16, feature_dim).to(device)\n",
    "                fake_images = G_model(z).cpu()\n",
    "                fake_images = (fake_images + 1) / 2  # Denormalize\n",
    "                \n",
    "                fig, axs = plt.subplots(4, 4, figsize=(10, 10))\n",
    "                for i in range(4):\n",
    "                    for j in range(4):\n",
    "                        axs[i, j].imshow(fake_images[i*4 + j].permute(1, 2, 0))\n",
    "                        axs[i, j].axis('off')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'./logs/GAN_epoch_{epoch+1}.png')\n",
    "                plt.close()\n",
    "            if (epoch+1)%10==0:\n",
    "                torch.save(G_model.state_dict(), 'generator.pth')\n",
    "                torch.save(D_model.state_dict(), 'discriminator.pth')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(G_model.state_dict(), 'generator.pth')\n",
    "torch.save(D_model.state_dict(), 'discriminator.pth')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
